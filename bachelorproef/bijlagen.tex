\chapter{Bijlagen}
\label{ch:bijlagen}

\section{Flask code}
\label{bijlage:flask}
\begin{python}
from flask import Flask, render_template, url_for, request, redirect, jsonify
import os
from datetime import datetime
import Calculations
from Calculations import remove_uploads
import shutil

app = Flask(__name__)
app.config['UPLOAD_EXTENSIONS'] = ['.wav', '.mp3']


@app.route('/', methods=['POST', 'GET'])
def index():
   if request.method == 'POST':
        print("POST")
   else:
        return render_template('index.html')


@app.route('/detector', methods=['POST', 'GET'])
def detector():
   if request.method == 'POST':
        print("POST")
   else:
        return render_template('detector.html')


@app.route('/picture_old_woman', methods=['GET'])
def picture_old_woman():
   url = url_for('static', filename='img/rusthuis.jpg')
   print(url)
   return url


@app.route('/privacy', methods=['GET'])
def privacy():
    return render_template('privacy.html')


@app.route('/elderspeak', methods=['GET'])
def elderspeak():
    return render_template('elderspeak.html')


@app.route('/receive_elderspeak', methods=['POST'])
def receive_elderspeak():
   now = datetime.now()
   d1 = now.strftime("%Y%m%d%H%M%S")
   data = request.files['audio_data'].read()
   extra_data = request.form.get('extra_data', "0,0")
   extra_data = extra_data.split(',')
   extra_data = list(map(float, extra_data))
   pitch_normal, loudness_normal = extra_data
   file = f'./uploads/{d1}.wav'

   response_data = {"Hello": "World"}
   with open(os.path.abspath(file), 'wb') as f:
   f.write(data)

   total_text = Calculations.speech_recognition(file)
   total_text = Calculations.replace_hey(total_text)
   verkleinwoorden = Calculations.verkleinwoorden(total_text)
   herhalingen = Calculations.herhalende_zinnen(total_text)
   pitch = Calculations.make_text_compare(pitch_normal,
   Calculations.calculate_pitch(Calculations.maketempfile_wav(file)),
        100,
       '<span class="text-danger">Hoger</span>',
       '<span class="text-success">Lager of niet significant hoger.</span>')
   loudness = Calculations.make_text_compare(pitch_normal,
       Calculations.loudness(Calculations.maketempfile_wav(file)),
       4,
       '<span class="text-danger">Luider</span>',
       '<span class="text-success">Stiller of niet significant luider.</span>')
   collectieve_voornaamwoorden = Calculations.collectieve_voornaamwoorden(total_text)
   tussenwerpsels = Calculations.tussenwerpsels(total_text)

   response_data["speech_recognition"] = total_text
   response_data["verkleinwoorden"] = verkleinwoorden
   response_data["herhalingen"] = herhalingen
   response_data["pitch"] = pitch
   response_data["loudness"] = loudness
   response_data["collectieve_voornaamwoorden"] = collectieve_voornaamwoorden
   response_data["tussenwerpsels"] = tussenwerpsels

   # return render_template('results.html', text=total_text)
   # laatste stap!

   shutil.rmtree('./uploads/chunks')
   if os.path.exists(file):
        os.remove(file)

   try:
        remove_uploads()
   except Exception as e:
        print(f"Fout bij het verwijderen van de tempfiles: {e}")

   response = jsonify(response_data)
   response.headers.add('Access-Control-Allow-Origin', '*')
   # remove_uploads()
   return response


@app.route('/receive_normal', methods=['POST'])
def receive_normal():
   now = datetime.now()
   d1 = now.strftime("%Y%m%d%H%M%S")
   file = f'./uploads/{d1}.wav'
   data = request.files['audio_data'].read()

   response_data = {"Hello": "World"}
   with open(os.path.abspath(file), 'wb') as f:
   f.write(data)

   print("PITCH BEREKENEN")
   pitch = Calculations.calculate_pitch(Calculations.maketempfile_wav(file))
   loudness = Calculations.loudness(Calculations.maketempfile_wav(file))

   response_data["pitch"] = pitch
   response_data["loudness"] = loudness

   if os.path.exists(file):
        os.remove(file)

   print(response_data)
   response = jsonify(response_data)
   response.headers.add('Access-Control-Allow-Origin', '*')
   # remove_uploads()
   return response


if __name__ == "__main__":
   try:
        app.run(
            debug=False,
            host='0.0.0.0'
        )
   finally:
        remove_uploads()

\end{python}

\section{Speech Recognition}
\label{bijlage:speech_recognition}
\begin{python}
def speech_recognition(file):
    try:

        print(file, ' to chunks')
        AudioSegment.converter = which("ffmpeg")
        myaudio = AudioSegment.from_file(file)
        channel_count = myaudio.channels  # Get channels
        sample_width = myaudio.sample_width  # Get sample width
        duration_in_sec = len(myaudio) / 1000  # Length of audio in sec
        sample_rate = myaudio.frame_rate

        print("sample_width=", sample_width)
        print("channel_count=", channel_count)
        print("duration_in_sec=", duration_in_sec)
        print("frame_rate=", sample_rate)
        bit_rate = 16  # assumption , you can extract from mediainfo("test.wav") dynamically

        wav_file_size = (sample_rate * bit_rate * channel_count * duration_in_sec) / 20
        print("wav_file_size = ", wav_file_size)

        file_split_size = 25000000  # 10Mb OR 10, 000, 000 bytes
        total_chunks = wav_file_size // file_split_size

        # Get chunk size by following method #There are more than one ofcourse
        # for  duration_in_sec (X) -->  wav_file_size (Y)
        # So   whats duration in sec  (K) --> for file size of 10Mb
        #  K = X * 10Mb / Y

        chunk_length_in_sec = math.ceil((duration_in_sec * 20000000) / wav_file_size)  # in sec
        chunk_length_ms = chunk_length_in_sec * 2000
        chunks = make_chunks(myaudio, chunk_length_ms)

        # Export all of the individual chunks as wav files

        if not os.path.exists('./uploads/chunks'):
            os.makedirs('./uploads/chunks')

        for i, chunk in enumerate(chunks):
            chunk_name = f"./uploads/chunks/chunck{i}.flac"
            print("exporting", chunk_name)
            chunk.export(chunk_name, format="flac")
    except Exception as error:
        error_message = f'Fout bij het bewerken van de audiofile: {error}.'
        print(error_message)
        return error_message

    DIR = './uploads/chunks/'

    numberOfItems = len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))])

    total_text = ""

    try:
        for i in range(numberOfItems):
        # Speech Recognition
        audio_file = sr.AudioFile(f'./uploads/chunks/chunck{i}.flac')
        with audio_file as source:
            r.adjust_for_ambient_noise(source)
            audio = r.record(source)
            text = r.recognize_google(audio_data=audio, language="nl-BE")
            total_text += " " + text
            print("######## Google Recognize ####################")
            print(text)
            print("##############################################")
            return total_text.strip()
    except Exception as error:
        error_message = f'Fout bij de spraakherkenning: {error}.'
        print(error_message)
        return error_message

\end{python}

\section{Verkleinwoorden}
\label{bijlage:verkleinwoorden}
\begin{python}
def verkleinwoorden(text):

    verkleinwoorden_array = []
    words = make_array_words(text)
    for word in words:
        if word is not None:
            if (len(word) > 3 and word not in geen_verkleinwoorden) and (
                word.endswith('je') or word.endswith('ke') or word.endswith('kes') or word.endswith('jes')):
                verkleinwoorden_array.append(word)
    if len(verkleinwoorden_array) == 0:
        return '<span class="text-success">Er zijn geen verkleinwoorden gevonden</span>'
    return highlight_words_in_text(text, set(verkleinwoorden_array))
\end{python}

\section{Herhalingen}
\label{bijlage:herhalingen}
\begin{python}
def herhalende_zinnen(text):

    words = make_array_words(text)

    cache = []
    toBeDeleted = []
    repetition = []

    for word in words:
        if word is not None:
            while len(cache) >= 25:
                cache.pop(0)
            if word not in nietzeggendewoorden:
                cache.append(word)

    sameequals = dict()

    sameequals = {word: cache.count(word) for word in cache}

    if sameequals is not None and len(sameequals) != 0:
        for word in sameequals:
            if sameequals[word] == 1:
                toBeDeleted.append(word)
            else:
                repetition.append(word)
        for word in toBeDeleted:
            del sameequals[word]

    if len(repetition) == 0:
        return '<span class="text-success">Er zijn geen herhalingen gevonden</span>'
    return highlight_words_in_text(text, set(repetition))
\end{python}

\section{Collectieve voornaamwoorden}
\label{bijlage:collectieve_voornaamwoorden}
\begin{python}
def collectieve_voornaamwoorden(text):
    collectieve_voornaamwoorden_array = []
    words = make_array_words(text)
    for word in words:
        if word is not None and word == "we":  # TODO uitbreiden?
            collectieve_voornaamwoorden_array.append(word)
    if len(collectieve_voornaamwoorden_array) == 0:
        return '<span class="text-success">Er werden geen collectieve voornaamwoorden gebruikt.</span>'
    c = dict(Counter(collectieve_voornaamwoorden_array))
    filtered_dict = {k: v for (k, v) in c.items() if v > 1}
    l = list(filtered_dict.keys())
    if len(l) == 0:
        return '<span class="text-success">Er werden niet genoeg collectieve voornaamwoorden gebruikt.</span>'
    return highlight_words_in_text(text, set(l))
\end{python}

\section{Tussenwerpsels}
\label{bijlage:tussenwerpsels}
\begin{python}
def tussenwerpsels(text):
    tussenwerpsels_array = []
    words = make_array_words(text)
    for word in words:
        if word is not None and word in tussenwerpels_woorden:
            tussenwerpsels_array.append(word)
    if len(tussenwerpsels_array) == 0:
        return '<span class="text-success">Er werden geen tussenwerpsels gebruikt.</span>'
    c = dict(Counter(tussenwerpsels_array))
    filtered_dict = {k: v for (k, v) in c.items() if v > 1}
    l = list(filtered_dict.keys())
    if len(l) == 0:
        return '<span class="text-success">Er werden niet genoeg tussenwerpsels gebruikt.</span>'
    return highlight_words_in_text(text, set(l))
\end{python}

\section{Toonhoogte}
\label{bijlage:toonhoogte}
\begin{python}
def calculate_pitch(wav_file):
    try:
        x, _ = librosa.load(wav_file, sr=16000)
        tmp_file = './uploads/tmp.wav'
        sf.write(tmp_file, x, 16000)

        chunk = 16384
        with wave.open(tmp_file, 'r') as wf:
            swidth = wf.getsampwidth()
            RATE = wf.getframerate()
            window = np.blackman(chunk)
            p = pyaudio.PyAudio()
            stream = p.open(format=
                p.get_format_from_width(wf.getsampwidth()),
                channels=wf.getnchannels(),
                rate=RATE,
                output=True)
            data = wf.readframes(chunk)
            freqlist = []
            while len(data) == chunk * swidth:
                # write data out to the audio stream
                stream.write(data)
                # unpack the data and times by the hamming window
                indata = np.array(wave.struct.unpack("%dh" % (len(data) / swidth),
                data)) * window
                # Take the fft and square each value
                fftData = abs(np.fft.rfft(indata)) ** 2
                # find the maximum
                which = fftData[1:].argmax() + 1
                # use quadratic interpolation around the max
                if which != len(fftData) - 1:
                    y0, y1, y2 = np.log(fftData[which - 1:which + 2:])
                    x1 = (y2 - y0) * .5 / (2 * y1 - y2 - y0)
                    # find the frequency and output it
                    thefreq = (which + x1) * RATE / chunk
                    print("The freq is %.0f Hz." % (thefreq))
                    freqlist.append(thefreq)
                else:
                    thefreq = which * RATE / chunk
                    print("The freq is %.0f Hz." % (thefreq))
                    freqlist.append(thefreq)
                # read some more data
                data = wf.readframes(chunk)
        if data:
            stream.write(data)
        freqlistavg = sum(freqlist) / len(freqlist)
        print("Average: %0.2f Hz." % (freqlistavg))
        stream.close()
        p.terminate()
        return round(freqlistavg, 2)
    except Exception as error:
        print(f'Fout bij het berekenen van de toonhoogte: {error}.')
        return -10000
    finally:
        if tmp_file is not None and os.path.exists(tmp_file):
            os.remove(tmp_file)
\end{python}

\section{Stemvolume}
\label{bijlage:stemvolume}
\begin{python}
def loudness(wav):
    data, rate = sf.read(wav)  # load audio (with shape (samples, channels))
    meter = pyln.Meter(rate)  # create BS.1770 meter
    loudness_range = meter.integrated_loudness(data)  # measure loudness
    if float('inf') == loudness_range:
        loudness_range = 10000
    elif float('-inf') == loudness_range:
        loudness_range = -10000
    return loudness_range
\end{python}

\section{Front-end}
\subsection{HTML code}
\label{bijlage:html}
\begin{python}
<div class="row">
<div class="col-12">
<h1>Elderspeak detector</h1>
<div class="row">
<div class="col-md-6">
<h3>Audio opnemen</h3>
<img src="{{ url_for('static', filename='img/jonge_mensen.jpg') }}" alt="rusthuis foto" class="img-fluid img-medium" id="picture">
<p id="tekst_bij_foto">Spreek in hoe je tegen deze vrienden zou praten:</p>
<button type="button" id="btn-record" class="btn btn-primary">Standaard audio opnemen</button>
<div class="d-flex flex-column">
<p id="saved" class="text-primary hidden my-2">De audio is opgeslagen!</p>
<audio id=recordedAudio></audio>
</div>
</div>
<div class="col-md-6 hidden" id="eigenschappen_elderspeak">
<h3>Eigenschappen van <i>Elderspeak</i>:</h3>
<div id="loading_eigenschappen">
<div class="spinner-border" role="status">
<span class="visually-hidden">Loading...</span>
</div>
</div>
<div id="eigenschappen_content" class="hidden">
<div class="row" id="big-content"></div>
<div class="row" id="small-content"></div>
</div>
<div class="hidden text-danger" id="errors">Er zijn fouten in het verwerken van de data...</div>
<button class="btn btn-warning" id="reset">Opnieuw proberen</button>
</div>
</div>

</div>
</div>
\end{python}


\subsection{Javascript code}
\label{bijlage:javascript}
\begin{python}
navigator.mediaDevices.getUserMedia({audio:true})
.then(stream => {handlerFunction(stream)})

function handlerFunction(stream) {
    rec = new MediaRecorder(stream);
    rec.ondataavailable = e => {
        audioChunks.push(e.data);
        if (rec.state === "inactive"){
            let blob = new Blob(audioChunks,{type:'audio/mp3'});
            let audioUrl = URL.createObjectURL(blob);
            let recordedAudio = document.getElementById('recordedAudio')
            recordedAudio.src = audioUrl;
            recordedAudio.controls=true;
            recordedAudio.autoplay=true;
            sendData(blob, btn_record.innerText.toLowerCase())
        }
    }
}

let loading_eigenschappen = document.getElementById('loading_eigenschappen');
const btn_record = document.getElementById('btn-record');
const picture = document.getElementById('picture');
const tekst_bij_foto = document.getElementById('tekst_bij_foto');
const text_under_pic = document.getElementById('saved');
const big_content = document.getElementById('big-content');
const small_content = document.getElementById('small-content');

//normal parameters
let pitch_normal = 0;
let loudness_normal = 0;


function sendData(blob, kind) {
    let data_to_send = new FormData();
    data_to_send.append('audio_data', blob);
    if (kind.toLowerCase().includes("saved")){
        data_to_send.append('extra_data', [pitch_normal, loudness_normal])
        fetch('http://127.0.0.1:5000/receive_elderspeak', {
            method: 'POST',
            body: data_to_send
        }).then(response => {
            console.log("||||||||||||||||||||||||||||||||||")
            console.log(response)
            return response.json();
        }).then(json => {
            console.log("&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&")
            console.log(json)
            big_content.insertAdjacentHTML("beforeend", `<div><h4>Wat heb je gezegd?</h4><p>${json['speech_recognition']}</p></div>`);
            big_content.insertAdjacentHTML("beforeend", `<div><h4>Verkleinwoorden:</h4><p>${json['verkleinwoorden']}</p></div>`);
            big_content.insertAdjacentHTML("beforeend", `<div><h4>Herhalingen:</h4><p>${json['herhalingen']}</p></div>`);
            big_content.insertAdjacentHTML("beforeend", `<div><h4>Collectieve voornaamwoorden:</h4><p>${json['collectieve_voornaamwoorden']}</p></div>`);
            big_content.insertAdjacentHTML("beforeend", `<div><h4>Tussenwerpsels:</h4><p>${json['tussenwerpsels']}</p></div>`);

            small_content.insertAdjacentHTML("beforeend", `<div class="col-6"><h4>Stemfrequentie:</h4><p>${json['pitch']}</p></div>`);
            small_content.insertAdjacentHTML("beforeend", `<div class="col-6"><h4>Stemvolume:</h4><p>${json['loudness']}</p></div>`);

            loading_eigenschappen.classList.add('hidden');
            document.getElementById('eigenschappen_content').classList.remove('hidden');
        }).catch((error) => {
            document.getElementById('errors').classList.remove('hidden');
            loading_eigenschappen.classList.add('hidden');
            console.log(error);
        });
    } else {
        fetch('http://127.0.0.1:5000/receive_normal', {
            method: 'POST',
            body: data_to_send
        }).then(response => {
            return response.json();
        }).then(json => {
            btn_record.disabled = false;
            pitch_normal = json['pitch'];
            loudness_normal = json['loudness'];
        }).catch((error) => {
            console.log(error)
        });
    }

}

function start_audio(text_after){
    audioChunks = [];
    rec.start();
    btn_record.classList.remove("btn-primary");
    btn_record.classList.add("btn-warning");
    btn_record.innerText = text_after
}
function stop_audio(innertext, text_after){
    if (innertext === "stop standaard opname") {
        document.getElementById('saved').classList.remove('hidden');
        picture.src = "/static/img/rusthuis.jpg";
        tekst_bij_foto.innerText = "Spreek in hoe je tegen deze bejaarde dame zou praten:";
    } else {
        loading_eigenschappen.classList.remove('hidden');
        document.getElementById('eigenschappen_elderspeak').classList.remove('hidden');
        btn_record.disabled = true;
    }
    rec.stop();
    btn_record.classList.remove("btn-warning");
    btn_record.classList.add("btn-primary");
    btn_record.innerText = text_after;
}

btn_record.addEventListener('click', () => {
    if (btn_record.innerText.toLowerCase() === "standaard audio opnemen"){
        start_audio("Stop standaard opname")
    } else if (btn_record.innerText.toLowerCase() === "stop standaard opname"){
        stop_audio("stop standaard opname", "Elderspeak audio opnemen")
        btn_record.disabled = true;
    } else if (btn_record.innerText.toLowerCase() === "elderspeak audio opnemen"){
        start_audio("Stop elderspeak audio opname")
    } else if (btn_record.innerText.toLowerCase() === "stop elderspeak audio opname"){
        stop_audio("stop elderspeak audio opname", "Saved")
    }

});

document.getElementById('reset').addEventListener('click', () => {
    location.reload()
})
\end{python}

